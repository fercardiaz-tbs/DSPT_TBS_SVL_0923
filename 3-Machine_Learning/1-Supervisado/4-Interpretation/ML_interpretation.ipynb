{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Interpretabilidad de los modelos de machine learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué es?**\n",
    "\n",
    "Serie de técnicas que asignan puntuaciones a las variables independientes de un modelo predictivo en función de su importancia relativa al realizar una predicción sobre la variable dependiente o target. \n",
    "\n",
    "IMPORTANTE: Antes de obtener el feature importance siempre hay que evaluar la capacidad predictiva del modelo implementado.\n",
    "\n",
    "**Tipos**\n",
    "\n",
    "1. Métodos \"built in\" en modelos intrinsecamente intepretables (ya vistos al estudiar los modelos lineales y los modelos basados en árboles de decision). \n",
    "\n",
    "2. Permutation importance\n",
    "\n",
    "3. Drop columns importance\n",
    "\n",
    "4. Shap values\n",
    "\n",
    "\n",
    "Para todos los ejemplos utilizaremos el dataset de Boston de Skalearn, que plantea un problema de regresión. La descripción de las variables de entrada se puede encontrar [aquí](https://scikit-learn.org/stable/datasets/toy_dataset.html#boston-dataset)\n",
    "\n",
    "La métrica que utilizaremos es el .score() de los modelos de regresión, es decire, el [R2 score](https://scikit-learn.org/stable/modules/model_evaluation.html#r2-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos el Boston dataset de Skalearn\n",
    "boston = load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construimos el dataframe para echarle un vistazo\n",
    "\n",
    "boston_df = pd.DataFrame(boston.data,                      \n",
    "                         columns=boston.feature_names)\n",
    "boston_df[\"MEDV\"]= boston.target\n",
    "\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos que aspecto tiene la relación entre las variables \n",
    "#con una matriz de correlación\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "sns.heatmap(boston_df.corr(),\n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            center=0,\n",
    "            cmap=sns.diverging_palette(220, 20, as_cmap=True),\n",
    "            square=True,\n",
    "            annot=True,\n",
    "            linewidths=.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Espliteamos para montar el modelo\n",
    "\n",
    "X = boston_df.drop(\"MEDV\", axis = 1)\n",
    "y = boston_df[\"MEDV\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest features importances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementamos un random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "rnd_reg = RandomForestRegressor(n_estimators = 200, \n",
    "                                max_depth = 4,\n",
    "                                random_state = 42)\n",
    "rnd_reg.fit(X_train, y_train)\n",
    "\n",
    "print(\"R2 score train\",rnd_reg.score(X_train,y_train))\n",
    "print(\"R2 score test\",rnd_reg.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos el feature_importances\n",
    "rnd_reg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_rnd= pd.DataFrame(rnd_reg.feature_importances_,\n",
    "                          boston.feature_names, \n",
    "                          columns = [\"Feature imp. RND\"]).sort_values(\"Feature imp. RND\", ascending=False)\n",
    "fi_rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizamos\n",
    "fi_rnd.sort_values(\"Feature imp. RND\").plot.barh(y='Feature imp. RND');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementamos el permutation importance\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "perm_train = permutation_importance(estimator=rnd_reg,\n",
    "                                    X = X_train,\n",
    "                                    y = y_train,\n",
    "                                    n_repeats = 10,\n",
    "                                    random_state=42,\n",
    "                                    scoring=\"r2\")\n",
    "\n",
    "#n_repeats = Number of times to permute a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el permutation importance para cada variable, como la media del impacto de las permutaciones de sus valores sobre el rendimiento del modelo (r2) a lo largo de las repeticiones efectuadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Raw permutation importance scores (13 features * 10 permutaciones)\n",
    "perm_train.importances.size\n",
    "### CODE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of feature importance over n_repeats.\n",
    "perm_train.importances_mean\n",
    "### CODE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Montamos el dataframe\n",
    "df_perm_train = pd.DataFrame(perm_train.importances_mean,\n",
    "                          boston.feature_names, \n",
    "                          columns = [\"Feature imp. RND\"]).sort_values(\"Feature imp. RND\", ascending=False)\n",
    "### CODE ####\n",
    "df_perm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE ####\n",
    "#Visualizamos\n",
    "df_perm_train.sort_values(\"Feature imp. RND\").plot.barh(y='Feature imp. RND');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos el permutation importance sobre los datos de test\n",
    "perm_test = permutation_importance(estimator=rnd_reg,\n",
    "                                    X = X_test,\n",
    "                                    y = y_test,\n",
    "                                    n_repeats = 10,\n",
    "                                    random_state=42,\n",
    "                                    scoring=\"r2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo pasamos a un dataframe\n",
    "df_perm_test = pd.DataFrame(perm_test.importances_mean,\n",
    "                          boston.feature_names, \n",
    "                          columns = [\"Feature imp. RND\"]).sort_values(\"Feature imp. RND\", ascending=False)\n",
    "### CODE ####\n",
    "df_perm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficamos\n",
    "df_perm_test.sort_values(\"Feature imp. RND\").plot.barh(y='Feature imp. RND');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero vemos como se haría manualmente\n",
    "\n",
    "from sklearn.base import clone \n",
    "\n",
    "# Create un unfitted model with the exact same specification as the one initially trained\n",
    "model_clone = clone(rnd_reg)\n",
    "# set random_state for comparability\n",
    "model_clone.random_state = 42\n",
    "# training and scoring the benchmark model\n",
    "model_clone.fit(X_train, y_train)\n",
    "baseline_score = model_clone.score(X_train, y_train)\n",
    "# list for storing feature importances\n",
    "importances = []\n",
    "    \n",
    "# iterating over all columns and storing feature importance (difference between benchmark and new model)\n",
    "for col in X_train.columns:\n",
    "    model_clone = clone(rnd_reg)\n",
    "    model_clone.random_state = 42\n",
    "    model_clone.fit(X_train.drop(col, axis = 1), y_train)\n",
    "    drop_col_score = model_clone.score(X_train.drop(col, axis = 1), y_train)\n",
    "    importances.append(baseline_score - drop_col_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col_manual = pd.DataFrame(importances, \n",
    "                              X_train.columns, \n",
    "                              columns = [\"Drop columns importance\"]).sort_values(\"Drop columns importance\", ascending = False)\n",
    "drop_col_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficamos\n",
    "drop_col_manual.plot.barh(y= \"Drop columns importance\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(rnd_reg)\n",
    "shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X, plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
