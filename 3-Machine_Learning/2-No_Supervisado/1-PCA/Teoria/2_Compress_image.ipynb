{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical digital image is made by stacking Red Blue and Green pixel arrays of intensities ranging from 0 to 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/RGB.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A grayscale image does not contain color but only shades of gray. The pixel intensity in a grayscale image varies from black (0 intensity) to white (255 full intensity) to make it what we usually call as a Black & White image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digits dataset is a grayscale image dataset of handwritten digit having 1797 8×8 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    " \n",
    "digits = load_digits()\n",
    "data = digits.data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.datasets module makes it quick to import digits data by importing load_digits class from it. The shape of the digit data is (1797, 64). 8×8 pixels are flattened to create a vector of length 64 for every image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking a sample image to view\n",
    "#Remember image is in the form of numpy array.\n",
    "image_sample = data[0,:].reshape(8,8)\n",
    "image_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_sample, cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using PCA, let’s reduce the image dimensions from 64 to just 2 so that we can visualize the dataset using a Scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(2)\n",
    "converted_data = pca.fit_transform(digits.data)\n",
    "\n",
    "converted_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass a float value less than 1 instead of an integer number. i.e. PCA(0.90) this means the algorithm will find the principal components which explain 90% of the variance in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.figure(figsize = (10,6))\n",
    "c_map = plt.cm.get_cmap('jet', 10)\n",
    "plt.scatter(converted_data[:, 0], converted_data[:, 1], s = 15,\n",
    "            cmap = c_map , c = digits.target)\n",
    "plt.colorbar()\n",
    "plt.xlabel('PC-1') , plt.ylabel('PC-2')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another cool application of PCA is in Image compression. Let’s have a look at how can we achieve this with python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the image \n",
    "img = cv2.imread('img/my_doggo_sample.jpeg')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(rgb_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "793*1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the image in R,G,B arrays.\n",
    "blue, green, red = cv2.split(img)\n",
    "\n",
    "#it will split the original image into Blue, Green and Red arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_not_compressed = cv2.merge([red,green,blue])\n",
    "#viewing the not compressed image\n",
    "plt.imshow(img_not_compressed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_not_compressed = cv2.merge([blue, green, red])\n",
    "#viewing the not compressed image\n",
    "plt.imshow(img_not_compressed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV will split into Blue, Green, and Red channels instead of Red, Blue, and Green. Be very careful of the sequence here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PCA with first 20 principal components\n",
    "pca = PCA(20)\n",
    " \n",
    "#Applying to red channel and then applying inverse transform to transformed array.\n",
    "red_transformed = pca.fit_transform(red)\n",
    "print('red_transformed.shape:', red_transformed.shape)\n",
    "red_inverted = pca.inverse_transform(red_transformed)\n",
    "print('red_inverted.shape:', red_inverted.shape)\n",
    "\n",
    "#Applying to Green channel and then applying inverse transform to transformed array.\n",
    "green_transformed = pca.fit_transform(green)\n",
    "print('green_transformed.shape:', green_transformed.shape)\n",
    "green_inverted = pca.inverse_transform(green_transformed)\n",
    "print('green_inverted.shape:', green_inverted.shape)\n",
    " \n",
    "#Applying to Blue channel and then applying inverse transform to transformed array.\n",
    "blue_transformed = pca.fit_transform(blue)\n",
    "print('blue_transformed.shape:', blue_transformed.shape)\n",
    "blue_inverted = pca.inverse_transform(blue_transformed)\n",
    "print('blue_inverted.shape:', blue_inverted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the process of reconstructing the original dimensions from the reduced dimensions, some information is lost as we keep only selected principal components, 20 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_compressed = (cv2.merge([red_inverted, green_inverted, blue_inverted])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking the inverted arrays using dstack function. Here it is important to specify the datatype of our arrays, as most images are of 8 bit. Each pixel is represented by one 8-bit byte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewing the compressed image\n",
    "plt.imshow(img_compressed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above is what we get when considering just 20 Principal components.\n",
    "\n",
    "If we increase the number of Principal components the output image will get clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Now check with how many Principal Components your eyes can't see the difference with the original!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) The dog should not be so blue, fix it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PCA with first 20 principal components\n",
    "pca = PCA(300)\n",
    " \n",
    "#Applying to red channel and then applying inverse transform to transformed array.\n",
    "red_transformed = pca.fit_transform(red)\n",
    "print('red_transformed.shape:', red_transformed.shape)\n",
    "red_inverted = pca.inverse_transform(red_transformed)\n",
    "print('red_inverted.shape:', red_inverted.shape)\n",
    "\n",
    "#Applying to Green channel and then applying inverse transform to transformed array.\n",
    "green_transformed = pca.fit_transform(green)\n",
    "print('green_transformed.shape:', green_transformed.shape)\n",
    "green_inverted = pca.inverse_transform(green_transformed)\n",
    "print('green_inverted.shape:', green_inverted.shape)\n",
    " \n",
    "#Applying to Blue channel and then applying inverse transform to transformed array.\n",
    "blue_transformed = pca.fit_transform(blue)\n",
    "print('blue_transformed.shape:', blue_transformed.shape)\n",
    "blue_inverted = pca.inverse_transform(blue_transformed)\n",
    "print('blue_inverted.shape:', blue_inverted.shape)\n",
    "\n",
    "img_compressed = (cv2.merge([red_inverted, green_inverted, blue_inverted])).astype(np.uint8)\n",
    "\n",
    "#viewing the compressed image\n",
    "plt.imshow(img_compressed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "90139cb9a825bf3d63f6f6704e828dbd1ff7edbd4d0c6e906a71235d6efc74af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
