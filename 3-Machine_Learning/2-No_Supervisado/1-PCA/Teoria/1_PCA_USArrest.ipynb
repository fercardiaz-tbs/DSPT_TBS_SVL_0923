{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "from matplotlib import style\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "USArrests = sm.datasets.get_rdataset(\"USArrests\", \"datasets\")\n",
    "datos = USArrests.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------------------')\n",
    "print('Media de cada variable')\n",
    "print('----------------------')\n",
    "datos.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-------------------------')\n",
    "print('Varianza de cada variable')\n",
    "print('-------------------------')\n",
    "datos.var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no se estandarizan las variables para que tengan media cero y desviación estándar de uno antes de realizar el estudio PCA, la variable Assault, que tiene una media y dispersión muy superior al resto, dominará la mayoría de las componentes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento modelo PCA con escalado de los datos\n",
    "# ==============================================================================\n",
    "pca_pipe = make_pipeline(StandardScaler(), PCA(n_components=4))\n",
    "pca_pipe.fit(datos)\n",
    "\n",
    "modelo_pca = pca_pipe['pca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_pipe['pca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Se convierte el array a dataframe para añadir nombres a los ejes.\n",
    "pd.DataFrame(\n",
    "    data = modelo_pca.components_,\n",
    "    columns = datos.columns,\n",
    "    index = ['PC1', 'PC2', 'PC3', 'PC4']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizar con detalle el vector de loadings que forma cada componente puede ayudar a interpretar qué tipo de información recoge cada una de ellas. Por ejemplo, la primera componente es el resultado de la siguiente combinación lineal de las variables originales:\n",
    "\n",
    "y = a + b*x1 + c*x2 ...\n",
    "\n",
    "PC1= 0.535899 Murder+0.583184 Assault+0.278191 UrbanPop+0.543432 Rape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La influencia de las variables en cada componente analizarse visualmente con un gráfico de tipo heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap componentes\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 4))\n",
    "componentes = modelo_pca.components_\n",
    "plt.imshow(componentes.T, cmap='seismic', aspect='auto')\n",
    "plt.yticks(range(len(datos.columns)), datos.columns)\n",
    "plt.xticks(range(len(datos.columns)), np.arange(modelo_pca.n_components_) + 1)\n",
    "plt.grid(False)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porcentaje de varianza explicada por cada componente\n",
    "# ==============================================================================\n",
    "print('----------------------------------------------------')\n",
    "print('Porcentaje de varianza explicada por cada componente')\n",
    "print('----------------------------------------------------')\n",
    "#### CODE ####\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 4))\n",
    "ax.bar(\n",
    "    x      = np.arange(modelo_pca.n_components_) + 1,\n",
    "    height = modelo_pca.explained_variance_ratio_\n",
    ")\n",
    "\n",
    "for x, y in zip(np.arange(len(datos.columns)) + 1, modelo_pca.explained_variance_ratio_):\n",
    "    label = round(y, 2)\n",
    "    ax.annotate(\n",
    "        label,\n",
    "        (x,y),\n",
    "        textcoords=\"offset points\",\n",
    "        xytext=(0,10),\n",
    "        ha='center'\n",
    "    )\n",
    "\n",
    "ax.set_xticks(np.arange(modelo_pca.n_components_) + 1)\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.set_title('Porcentaje de varianza explicada por cada componente')\n",
    "ax.set_xlabel('Componente principal')\n",
    "ax.set_ylabel('Por. varianza explicada');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_pca.explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porcentaje de varianza explicada acumulada\n",
    "# ==============================================================================\n",
    "prop_varianza_acum = modelo_pca.explained_variance_ratio_.cumsum()\n",
    "print('------------------------------------------')\n",
    "print('Porcentaje de varianza explicada acumulada')\n",
    "print('------------------------------------------')\n",
    "print(prop_varianza_acum)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 4))\n",
    "ax.plot(\n",
    "    np.arange(len(datos.columns)) + 1,\n",
    "    prop_varianza_acum,\n",
    "    marker = 'o'\n",
    ")\n",
    "\n",
    "for x, y in zip(np.arange(len(datos.columns)) + 1, prop_varianza_acum):\n",
    "    label = round(y, 2)\n",
    "    ax.annotate(\n",
    "        label,\n",
    "        (x,y),\n",
    "        textcoords=\"offset points\",\n",
    "        xytext=(0,10),\n",
    "        ha='center'\n",
    "    )\n",
    "    \n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.set_xticks(np.arange(modelo_pca.n_components_) + 1)\n",
    "ax.set_title('Porcentaje de varianza explicada acumulada')\n",
    "ax.set_xlabel('Componente principal')\n",
    "ax.set_ylabel('Por. varianza acumulada');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se empleasen únicamente las dos primeras componentes se conseguiría explicar el 87% de la varianza observada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado el modelo, con el método transform() se puede reducir la dimensionalidad de nuevas observaciones proyectándolas en el espacio definido por las componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proyección de las observaciones de entrenamiento\n",
    "# ==============================================================================\n",
    "pca_pipe = make_pipeline(StandardScaler(), PCA(n_components=2))\n",
    "modelo_pca = pca_pipe['pca']\n",
    "proyecciones = pca_pipe.fit_transform(X=datos)\n",
    "proyecciones = pd.DataFrame(\n",
    "    proyecciones,\n",
    "    columns = ['PC1', 'PC2'],\n",
    "    index   = datos.index\n",
    ")\n",
    "proyecciones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La transformación es el resultado de multiplicar los vectores que definen cada componente con el valor de las variables. Puede calcularse de forma manual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proyecciones = np.dot(modelo_pca.components_, scale(datos).T)\n",
    "proyecciones = pd.DataFrame(proyecciones, index = ['PC1', 'PC2'])\n",
    "proyecciones = proyecciones.transpose().set_index(datos.index)\n",
    "proyecciones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede revertirse la transformación y reconstruir el valor inicial con el método inverse_transform(). Es importante tener en cuenta que, la reconstrucción, solo será completa si se han incluido todas las componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recostruccion de las proyecciones\n",
    "# ==============================================================================\n",
    "reconstruccion = pca_pipe.inverse_transform(proyecciones)\n",
    "reconstruccion = pd.DataFrame(\n",
    "    reconstruccion,\n",
    "    columns = datos.columns,\n",
    "    index = datos.index\n",
    ")\n",
    "\n",
    "print('------------------')\n",
    "print('Valores reconstruidos')\n",
    "print('------------------')\n",
    "display(reconstruccion.head())\n",
    "\n",
    "print('---------------------')\n",
    "print('Valores originales')\n",
    "print('---------------------')\n",
    "display(datos.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "90139cb9a825bf3d63f6f6704e828dbd1ff7edbd4d0c6e906a71235d6efc74af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
