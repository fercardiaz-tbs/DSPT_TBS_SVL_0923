{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ded0783b",
   "metadata": {},
   "source": [
    "### Pyspark Handling Missing Values\n",
    "- Eliminar columnas\n",
    "- Eliminar Filas\n",
    "- Parámetros para el Dropping\n",
    "- Imputar valores nulos con la media, la mediana y la moda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff3cadd",
   "metadata": {},
   "source": [
    "#### CREAMOS LA SESIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e1b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e548e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885555b9",
   "metadata": {},
   "source": [
    "#### CARGAMOS EL DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5dfac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('data/test2.csv', header=True, inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9855000",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb5991f",
   "metadata": {},
   "source": [
    "La función drop() tiene varios parámetros, entre ellos \"how\", con valores \"any\" y \"all\".\n",
    "- how = 'any' elimina la columna si uno de los valores es nulo (any por defecto)\n",
    "- how = 'all' elimina la columna si todos los valores son nulos\n",
    "\n",
    "Otro parámetro es \"thresh\". Por ejemplo: thresh = 2, significa que se mantienen las filas con al menos 2 valores NO NULOS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433eb8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.na.drop(how = 'any', thresh = 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588fe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.na.drop(how = 'any', thresh = 3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca81f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.na.drop(how = 'any', thresh = 1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0535f4c1",
   "metadata": {},
   "source": [
    "El último parámetro es \"subset\". Con este, podemos decirle que elimine las columnas con valores nulos en una columna determinada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.na.drop(how = 'any', subset = ['Experience']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ef0db6",
   "metadata": {},
   "source": [
    "RELLENAR MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be913ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.na.fill('Missing Value').show() \n",
    "\n",
    "# también se podría poner df_pyspark.fillna().\n",
    "# Solo rellenará las columnas que comparten el tipo de valor. Si lo que queremos introducir es un string, solo lo sustituirá en aquellas\n",
    "# columnas que sean string. Esto es igual con las columnas numéricas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3cb9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distintos tipos en las columnas seleccionadas.\n",
    "\n",
    "df_pyspark.na.fill({'Name':'Missing Value', 'Experience':10}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5313f9d4",
   "metadata": {},
   "source": [
    "#### IMPUTAR VALORES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc8b4bf",
   "metadata": {},
   "source": [
    "Podemos sustituir los valores por el valor medio, mediana... de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ebf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_mean = Imputer(inputCols=['age', 'Experience', 'Salary'],\n",
    "                    outputCols = ['{}_imputed'.format(c) for c in ['age', 'Experience', 'Salary']]\n",
    "                    ).setStrategy('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d736a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_mean.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150dd612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "90139cb9a825bf3d63f6f6704e828dbd1ff7edbd4d0c6e906a71235d6efc74af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
