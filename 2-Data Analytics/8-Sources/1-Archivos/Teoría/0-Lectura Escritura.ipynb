{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imagen](./img/python.jpg)\n",
    "\n",
    "# Lectura Escritura\n",
    "\n",
    "En este módulo vas a ver diferentes maneras de leer y escribir datos desde archivos locales. Rara vez trabajarás únicamente con los datos que genere tu programa de Python, sino que lo normal será acudir a una fuente de datos, o leer de algún archivo.\n",
    "\n",
    "1. [Archivos](#1.-Archivos)\n",
    "2. [Abrir ficheros](#2.-Abrir-ficheros)\n",
    "3. [CSV](#3.-CSV)\n",
    "4. [Excel](#4.-Excel)\n",
    "5. [JSON](#5.-JSON)\n",
    "6. [TXT](#6.-TXT)\n",
    "7. [ZIP](#7.-ZIP)\n",
    "8. [pickle](#8.-pickle)\n",
    "9. [Encoding](#9.-Encoding)\n",
    "10. [Archivos y carpetas](#10.-Archivos-y-carpetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Archivos\n",
    "Antes de ir a leer o escribir archivos, es importante saber exáctamente qué es un archivo. **Un archivo es un conjunto de datos almacenados en el ordenador en forma de bits.** Los datos se organizan en un formato específico, pudiendo ser un archivo de texto, un ejecutable... pero en el fondo todos esos archivos se traducen a nivel binario para el procesado del ordenador. Los archivos se componen de:\n",
    "\n",
    "1. **Header**: metadatos del archivo (nombre, tamaño, tipo...)\n",
    "2. **Data**: contenido del archivo\n",
    "3. **End of file (EOF)**: caracter especial que indica el final del archivo.\n",
    "\n",
    "![imagen](./img/file.png)\n",
    "\n",
    "#### File path\n",
    "Hay tres elementos que tenemos que conocer cuando leamos un archivo:\n",
    "1. **Folder path**: en que lugar del ordenador está el archivo. Y no solo eso, si no en qué directorio está apuntando el programa de Python.\n",
    "2. **File name**\n",
    "3. **Extension**: lo que va después del punto\n",
    "\n",
    "Fíjate en la siguiente imagen:\n",
    "\n",
    "![imagen](./img/path.png)\n",
    "\n",
    "* Si estamos trabajando en el directorio *to*, accederemos a *cats.gif* como `cats.gif`\n",
    "* Si queremos leer *dog_breeds.txt*, hay que ir un directorio hacia atrás, `../dog_breeds.txt`\n",
    "* Y si queremos acceder a `animals.csv`, son dos directorios hacia atrás: `../../animals.csv`\n",
    "\n",
    "Siempre podemos poner la ruta absoluta (`C/Users/usuario/Archivos/Bootcamp/Python/animals.csv`) para el acceso a cada archivo, **aunque no es lo recomendable**.\n",
    "\n",
    "[Buena guía para iniciarse en la lectura/escritura de archivos con Python.](https://realpython.com/read-write-files-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Abrir ficheros\n",
    "A lo largo de este notebook verás diferentes funciones para leer archivos, en función de la extensión cada uno. Estas funciones provienen de otras librerías y nos facilitan mucho la vida a la hora de leer o escribir archivos. No obstante, Python tiene sus propias funciones *built-in*, con las que no es necesario utilizar otros paquetes. \n",
    "\n",
    "Para ello **usaremos la función `open`**, que devuelve un objeto de tipo `File`, con unos métodos y atributos propios empleados para obtener información de los archivos abiertos. `open` sigue la siguiente sitaxis:\n",
    "\n",
    "```Python\n",
    "file_object  = open(\"filename\", \"mode\")\n",
    "```\n",
    "\n",
    "El primer argumento es el nombre del archivo, mientras que en el modo tendremos que especificar si queremos leer, o escribir. Por defecto leerá, es decir, el parámetro valdrá *r*, de read. [Te dejo el enlace a la documentación para consultar el resto de modos](https://docs.python.org/3/library/functions.html#open).\n",
    "\n",
    "Vamos a probar a leer un archivo. La siguiente sintaxis de línea se utiliza porque en algún momento se tiene que cerrar el archivo. Se abre, leemos, realizamos operaciones, y cuando acaba el `with open()`, se cierra el archivo. **Leer y escribir mientras los archivos están abiertos nos dará errores**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dog_breeds.txt', 'r') as open_file:\n",
    "    all_text = open_file.read()\n",
    "    print(type(all_text))\n",
    "    print(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `.read()` nos devuelve un string con todo el texto, que no es lo ideal para tratar luego los datos.\n",
    "\n",
    "En el siguiente ejemplo vemos como también lo leemos, pero en este caso cada línea la guarda en una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dog_breeds.txt', 'r') as open_file:\n",
    "    all_text = open_file.readlines()\n",
    "    print(type(all_text))\n",
    "    print(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dog_breeds.txt', 'r') as open_file:\n",
    "    for line in open_file.readlines():\n",
    "        print(line, end = '')\n",
    "        \n",
    "print('Fin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dog_breeds.txt', 'r') as reader:\n",
    "    # Read and print the entire file line by line\n",
    "    for line in reader:\n",
    "        print(line, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos escribir. \n",
    "\n",
    "- Si el archivo __EXISTE__: te abre el archivo y puedes escribir en el \n",
    "- Si el archivo __NO EXISTE__: te CREA el archivo y te permite escribir en el \n",
    "\n",
    "__IMPORTANTE__: si pones en la ruta una carpeta que NO EXISTE, te dará error porque este metodo no crea CARPETAS, solo crea ARCHIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/generated/pregunta_marcos.txt', 'w') as new_file:\n",
    "    new_file.write(\"Esto se crea?\")\n",
    "    new_file.write(\"Segunda linea\")\n",
    "    new_file.write(\"Tercera linea\")\n",
    "    print(\"Ya se ha escrito\")\n",
    "\n",
    "\n",
    "with open(\"data/generated/pregunta_marcos.txt\", \"r\") as new_file:\n",
    "    linea = new_file.readlines()\n",
    "    print(linea)\n",
    "    print(type(linea))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    " <tr><td width=\"80\"><img src=\"./img/ejercicio.png\" style=\"width:auto;height:auto\"></td>\n",
    "     <td style=\"text-align:left\">\n",
    "         <h3>Ejercicio en clase: R/W Archivos</h3>\n",
    "\n",
    "Crear un archivo llamado `raza_perros._tu_nombre_` y escribir el contenido de `dog_breeds.txt` pero ordenado al revés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerda que puedes ver dónde estás con el comando `getcwd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CSV\n",
    "***Comma Separated Values*. Es el estándar de la industria que se utiliza para leer/escribir datos en formato tabla**, en dos dimensiones. Se llaman *Comma Separeted Values* ya que todos los valores de las columnas van separados por comas, y las filas por saltos de línea. **Su extension de archivo es `.csv`**. Además, el 99% de las veces llevan la cabecera de columnas en la primera línea. Aunque no siempre se dará el caso, depende de la manera en la que se haya generado el CSV.\n",
    "\n",
    "**Es el archivo más común utilizado para guardar datos tabulares, puesto que ocupa muy poco espacio** ya que es simplemente un archivo de texto plano, con todos los datos separados por el caracter coma. Y además, sencillo de entender, los datos no van en un árbol json o xml... Si lo abrimos como texto plano, son los datos separados por coma, tal cual. \n",
    "\n",
    "Por supuesto, tenemos el otro gran protagonista en cuanto a almacenamiento de datos en formato tabla, **el Excel**. A ver, son cosas diferentes. El Excel tiene sus formatos (.xlsx, .xls), que encima son muy eficientes ya que el dato va comprimido, pero no deja de ser un software de pago para tratar los datos, mientras que **el CSV es un formato estándar que se utiliza en todos los sistemas operativos para el exportado/importado de datos**.\n",
    "\n",
    "Como decíamos al principio, los CSVs se llaman *Comma Separated Values* porque todos los valores van separados por comas... bueno, esto no es del todo cierto ya que **puede haber otro caracter que no sea la coma**, como por ejemplo el punto y coma. ¿Por qué? Simplemente porque si tenemos datos decimales, separados por comas, no vamos a saber distinguir cuando una coma es de un decimal, o es el separador de columnas.\n",
    "\n",
    "**¿Cómo podemos leer un CSV en Python?** Con Pandas! [Aquí tienes la documentación](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/laliga.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parámetros interesantes del `read_csv()`**\n",
    "1. `filepath_or_buffer`: ruta donde está el CSV\n",
    "2. `sep`: el separador de los datos, por defecto es coma, pero podría ser otro como veremos en ejemplos posteriores.\n",
    "3. `header`: dónde se encuentran los nombre de columnas. Por defecto es en la primera línea.\n",
    "\n",
    "Probemos a leer el CSV desde otra ruta del ordenador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/laliga4.csv\",sep=\"~\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las columnas, la podremos usar como index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/laliga.csv', index_col = 'Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos pasar el índice a una nueva columna, simplemente creamos una columna nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['nueva columna'] = df.index\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos resetear también el índice, y poner ahi un numérico que vaya desde el 0 al número de filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resetear el index. Drop= True para que no lo conserve\n",
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Para cambiar el indice\n",
    "df.index = range(1, df.shape[0] + 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones\n",
    "print(df.shape) # Ambas\n",
    "print(df.shape[0]) # Filas\n",
    "print(df.shape[1]) # columnas\n",
    "print(len(df)) # Filas tambien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También es posible aplicarle nombres de columnas en la lectura de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/laliga.csv',\n",
    "                names = ['Indice', 'Temporada', 'Division', 'Jornada',\n",
    "                          'Equipo local', 'Equipo visitante', 'Goles local',\n",
    "                          'Goles visitante', 'fecha', 'timestamp'],\n",
    "                header = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos cambiar los tipos de los datos, en la propia lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas 2.0:\n",
    "df = pd.read_csv(\"data/laliga.csv\",\n",
    "                usecols = ['Unnamed: 0', 'division', 'localTeam'],\n",
    "                dtype = {'Unnamed: 0': object,\n",
    "                         'division': np.int64,\n",
    "                         'localTeam': object})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas 1.0:\n",
    "df = pd.read_csv(\"data/laliga.csv\",\n",
    "                usecols = ['Unnamed: 0', 'division', 'localTeam'],\n",
    "                dtype = {'Unnamed: 0': np.object,\n",
    "                         'division': np.int64,\n",
    "                         'localTeam': np.object})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo leer un archivo CSV que no esté separado por comas?**\n",
    "Probemos a leer un archivo CSV, que no tiene comas como delimitador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/laligaPC.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo lee todo como una única línea ya que no encuentra comas. **Se recomienda trajar con CSVs cuyo separador sea el ; así evitamos problemas por los decimales**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/laligaPC.csv\", sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Podemos tener otros caracteres que separen los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/laliga4.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/laliga4.csv\", sep='~')\n",
    "df.head()\n",
    "df = df.rename({'Unnamed: 0':'indice_chungo'},axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escritura de CSV**\n",
    "\n",
    "Para escribir un CSV usamos el método `to_csv()`. Tienes [el enlace a la documentación para ver más detalle](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/generated/laligaWrite.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"data/generated/laligaWrite.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/generated/laligaWrite.csv\", sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    " <tr><td width=\"80\"><img src=\"./img/ejercicio.png\" style=\"width:auto;height:auto\"></td>\n",
    "     <td style=\"text-align:left\">\n",
    "         <h3>Ejercicio CSV</h3>\n",
    "\n",
    "A partir de estas dos series, monta un Dataframe. Crea un CSV a partir de ese DataFrame y leelo a continuación\n",
    "         \n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poblacion = pd.Series({\"Madrid\": 6685471, \"Galicia\": 2698764,\n",
    "                       \"Murcia\": 1494442, \"Andalucia\": 8446561})\n",
    "\n",
    "\n",
    "superficie = pd.Series([8028, 29575, 11314, 87599],\n",
    "                       index = [\"Madrid\", \"Galicia\", \"Murcia\", \"Andalucia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Excel\n",
    "¿Qué empresa no trabaja con Excel? **Nos vamos a encontrar los formatos de datos de Excel en cualquier sitio**. Las extensiones de archivo más habituales son `.xlsx` y `.xls`. Por suerte, **`pandas` tiene métodos para leer los formatos de archivo de Excel**.\n",
    "\n",
    "El problema que presenta este tipo de lectura de datos es que **no es un formato tan cerrado como el CSV**. En el CSV tenemos una estructura compacta, con todos los datos separados por comas y con una línea de cabecera en la primera fila. El Excel permite tener datos en un formato mucho más flexible, con tablas en cualquier sitio de las hojas, información en varias hojas y demás.\n",
    "\n",
    "Teniendo esto en cuenta, y sabiendo bien el formato del Excel en cuestión, podremos leerlo sin problemas con `pandas`, debido a la cantidad de argumentos que tiene la función `read_excel`. [En la documentación tienes todo el detalle](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html).\n",
    "\n",
    "Leemos nuestro archivo de laliga, pero en este caso en Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/laliga.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No tenemos problemas cuando los datos están perfectos, con una única hoja, y empezando en la celda A1. ¿Qué argumentos nos pueden resultar útiles?\n",
    "\n",
    "1. `io`: dónde está el archivo\n",
    "2. `sheet_name`: el nombre de la hoja\n",
    "3. `header`: dónde está la cabecera\n",
    "4. `usecols`: indica el rango de columnas Excel en el que se encuentran. Por ejemplo: 'A:F'\n",
    "5. `skiprows`: filas que deberia ignorar\n",
    "\n",
    "Veamos más ejemplos. El Excel de `laliga.xlsx` tiene varias pestañas. Por defecto, lee la primera, `Hoja1`, pero podemos especificar otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/laliga.xlsx', sheet_name = 'Hoja2')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay algún problema con los datos. Las primeras líneas están en blanco en el Excel. Podemos, o bien ignorarlas, o indicarle donde está la cabecera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/laliga.xlsx', sheet_name = 'Hoja2', header = 2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro problema que nos puede surgir es que la tabla no esté ni en las primeas filas, ni en las primeras columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/laliga.xlsx',\n",
    "                   sheet_name = 'Hoja3',\n",
    "                  header = 2,\n",
    "                  usecols = 'B:K')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/laliga.xlsx',\n",
    "                   sheet_name = 'Hoja4',\n",
    "                  header = 3,\n",
    "                  usecols = 'C:L',\n",
    "                  )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/laliga.xlsx',\n",
    "                   sheet_name = 'Hoja5')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escritura de Excel**\n",
    "\n",
    "Al igual que con el CSV, tenemos el método `to_excel()`, para escribir el `DataFame` en un archivo Excel. **Recuerda poner la extensión del Excel (.xlsx) en el nombre del archivo**. Tienes [el enlace a la documentación para ver más detalle](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('data/generated/laligaExcelWrite.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. JSON\n",
    "***JavaScript Objet Notation* es otro formato de texto plano que se utiliza para el itercambio de datos**. Originalmente se utilizaba como notación literal de objetos en JavaScript, pero actualmente es un formato de datos independiente del lenguaje. JavaScript es un lenguaje de programción web, por lo que JSON se utiliza mucho en el intercambio de objetos entre cliente y servidor.\n",
    "\n",
    "**¿Qué diferencia hay con un CSV o un Excel?** Ya no tenemos esa estructura de fila/columna, sino que ahora es un formato tipo clave/valor, como si fuese un diccionario. En una tabla en la fila 1, columna 1, tienes un valor. En un JSON no, en la clave \"mi_clave\" puedes tener almacenado un valor, una lista o incluso un objeto. Salimos del formato tabla al que estamos acostubrados para ganar en flexibilidad.\n",
    "\n",
    "Un JSON tiene la siguiente pinta:\n",
    "\n",
    "![imagen](./img/json_image.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  {\n",
    "        \"firstName\": \"Jane\",\n",
    "        \"lastName\": \"Doe\",\n",
    "        \"hobbies\": [\"running\", \"sky diving\", \"singing\"],\n",
    "        \"age\": 35,\n",
    "        \"children\": [\n",
    "                        {\n",
    "                            \"firstName\": \"Alice\",\n",
    "                            \"age\": 6\n",
    "                        },\n",
    "                        {\n",
    "                            \"firstName\": \"Bob\",\n",
    "                            \"age\": 8\n",
    "                        }\n",
    "                    ]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hobbies'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Puedo guardar el JSON en un archivo. Para ello, usamos la librería `json`**, que viene incluida en la instalación de Anaconda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/generated/data_file.json\", \"w\") as write_file:\n",
    "    json.dump(data, write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O también objetos de una clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Persona:\n",
    "    \n",
    "    def __init__(self, firstName, lastName, hobbies):\n",
    "        self.firstName = firstName\n",
    "        self.lastName = lastName\n",
    "        self.hobbies = hobbies\n",
    "        \n",
    "pers1 = Persona(\"Pepe\", \"Carrasco\", [\"Bricolaje\", \"Tenis\"])\n",
    "pers2 = Persona(\"Jose\", \"Carrasco\", [\"Bricolaje\", \"Tenis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers1.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo puedo guardar en un archivo *pepe.json*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/generated/pepe.json\", \"w\") as write_file:\n",
    "    json.dump(pers2.__dict__, write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego lo puedo volver a cargar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/generated/pepe.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "print(data)\n",
    "print(data['firstName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivo musical instruments\n",
    "with open(\"data/Musical_Instruments_5.json\", \"r\") as json_file:\n",
    "    res = []\n",
    "    for line in json_file:\n",
    "        data = json.loads(line)\n",
    "        res.append(data)\n",
    "\n",
    "print(len(res))   \n",
    "print(res[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si un archivo tiene UN unico diccionario:  \n",
    "```\n",
    "{}\n",
    "```\n",
    "- Se abre con el `with open() as alias` y usais `json.load(alias)`\n",
    "\n",
    "Si el archivo tiene MAS de un diccionario:  \n",
    "```\n",
    "{}  \n",
    "{} \n",
    "```\n",
    "- Se abre con el `with open() as alias`, luego ITERAIS con un `for linea in alias` y usais `json.loads(linea)`\n",
    "- Lo cargais con pandas con `pd.read_json(archivo,lines=True)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el siguiente ejemplo, utilizamos `pandas` y leeremos el archivo JSON, de tal manera que nos transforme los datos en formato tabla, en un `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/Musical_Instruments_5.json', lines = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. TXT\n",
    "**Son simplemente archivos donde hay texto**. Hemos visto que los CSVs y los JSON tienen su propio formato y extension. En el caso del .txt no tienen ninguno específico aunque no quita para que sus elementos estén separados por comas, y se pueda leer igualmente como si fuese un CSV.\n",
    "\n",
    "Cuando almancenamos datos siempre tienen una estructura, por lo que aunque sea un `.txt`, llevará los datos en formato json, separados por comas, tabulaciones, puntos y comas...\n",
    "\n",
    "Por ejemplo, si tenemos los datos de la liga guardados en un `.txt`, separados por tabulaciones, lo podremos leer con el `pd.read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/laligaTXT.txt', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerda que la separación por tabulaciones, también tiene su propia extensión: el `.tsv`, que igualmente lo podremos leer con `read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/laligaTSV.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `read_csv()` no se ciñe únicamente a leer CSVs, sino a prácticamente cualquier archivo que lleve un acarácter concreto en la separación de sus campos. Si conocemos ese caracter, sabremos leer el archivo con `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ZIP\n",
    "En ocasiones los datos que recibimos en nuestros programas están comprimidos, ya sea en un formato `.zip`, `.rar`, `.7z`, u otro tipo de archivo.\n",
    "\n",
    "En este apartado verás un ejemplo de cómo descomprimir archivos `.zip`. Para ello empleamos la librería `zipfile` que viene incluida en la instalación de Anaconda. [Tienes el enlace a la documentación para más detalle](https://docs.python.org/3/library/zipfile.html#zipfile-objects).\n",
    "\n",
    "Para extraer todos los archivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('data/laligaZIP.zip') as zip_ref:\n",
    "    zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quieres descomprimir un archivo `.rar` [tendrás que descargarte un paquete como por ejemplo `unrar`.](https://pypi.org/project/unrar/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    " <tr><td width=\"80\"><img src=\"./img/ejercicio.png\" style=\"width:auto;height:auto\"></td>\n",
    "     <td style=\"text-align:left\">\n",
    "         <h3>Ejercicio zip</h3>\n",
    "\n",
    "Consulta la documentación para extraer un único archivo, por nombre\n",
    "         \n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. pickle\n",
    "**`pickle` es el módulo que nos permite serializar y deserializar un objeto de Pyhton**. Esta operación lo que hace es traducirlo a un stream de bytes.\n",
    "\n",
    "A efectos prácticos, lo que nos permite es guardar objetos de Python, y recuperarlos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre=\"renando\"\n",
    "apellidos=\"carrasian sevillino\"\n",
    "edad=\"poca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "df = pd.read_csv(\"data/laliga.csv\")\n",
    "\n",
    "with open('data/generated/pepe.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "with open('data/generated/importante', 'wb') as f:\n",
    "    #pickle.dump(pers1, f)\n",
    "    pickle.dump(df, f)\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/generated/importante', 'rb') as f:\n",
    "    a = pickle.load(f)\n",
    "    b = pickle.load(f)\n",
    "    #c = pickle.load(f)\n",
    "    \n",
    "print(a)\n",
    "print(b)\n",
    "# print(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Encoding\n",
    "\n",
    "\n",
    "**Los strings se almacenan internamente en un conjunto de bytes**, caracter a caracter. Esta operación es lo que se conoce como ***encoding***, mientras que pasar de bytes a string sería *decoding*. Bien, ¿y eso en qué nos afecta? Dependiendo del encoding, se suelen almacenar en un espacio de bits de 0 a 255, es decir, en esa combinación de bits tienen que entrar todos los caracteres del lenguaje.\n",
    "\n",
    "El problema es que en toda esa combinación de bits no entran todos los caracteres del planeta, por lo que **dependiendo del encoding que usemos, una combinación de bits significará una cosa u otra**. Por ejemplo, una A mayuscula será lo mismo en el encodig europeo que en el americano, pero los bits reservados para representar una Ñ, en el encodig americano se traduce en otro caracter.\n",
    "\n",
    "Por tanto, **hay que tener claro en qué encoding está el archivo y con qué encoding lo vamos a leer**. [En la documentación](https://docs.python.org/3/library/codecs.html#encodings-and-unicode) puedes realizar esta comprobación. Hay algunos que te tienen que ir sonando:\n",
    "\n",
    "1. 'utf-8': normalmente se trabaja con este encodig que engloba la mayor parte de caracteres.\n",
    "2. 'unicode': estándar universal con el que no deberiamos tener problemas.\n",
    "3. 'ascii': encoding americano. Solo tiene 128 caracteres.\n",
    "4. 'latin': para oeste de Europa, Oceanía y Latinoamérica\n",
    "\n",
    "![imagen](./img/encoding.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data/encoding.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.read_csv('data/encoding.csv', encoding = 'ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data/encoding.csv', encoding='iso8859_10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Archivos y carpetas\n",
    "Resulta de gran utilidad automatizar lecturas/escrituras/borrado/movimientos de archivos entre carpetas. Si tenemos un proceso definido en Python, podremos ejecutarlo tantas veces queramos y de este modo evitar dedicarle tiempo tareas tediosas y rutinarias. Para ello tendremos que apoyarnos en el módulo de Python `os`.\n",
    "\n",
    "Lo primero de todo es saber en qué directorio estamos trabajando. Esto es fundamental para elegir bien la ruta relativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() # == pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El directorio de trabajo lo podríamos cambiar si quisiéramos, por ejemplo, al escritorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('c:\\\\Users\\\\Usuario\\\\Desktop\\\\TheBridgeRepos\\\\Repo Bootcamp Sep23\\\\Profesor\\\\2-Data Analytics\\\\8-Sources\\\\1-Archivos\\\\Teoría\\\\data')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir() # == ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos juntar rutas en un único path. Realiza un concatenado con barras entendibles por Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath(\"10_minutes_to_pandas.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(\"C:/path/to/directory\", \"some_file.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quieres buscar algún tipo de archivo concreto, tienes varias opciones:\n",
    "- Buscar por nombre\n",
    "- Buscar por extensión\n",
    "\n",
    "En función de lo que encuentres, realizarás una operación u otra. Ahora bien, igualmente para buscar, tendrás que recorrer todos los archivos que estén en un directorio o en varios directorios. Para listar todos los ARCHIVOS y CARPETAS que hay en el directorio actual de trabajo, utilizamos `os.listdir()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a quedarme con todos los notebooks del actual directorio de trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir():\n",
    "    if i.endswith('.ipynb'):\n",
    "        print(\"Notebook\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quiero acceder sólo a los directorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir():\n",
    "    if '.' not in i:\n",
    "        print(\"directorio\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro método interesante para bucear en los archivos y carpetas de un directorio concreto es el `os.walk()`. Va a devoler un iterable que podremos recorrer en un for y obtener en formato tupla todos los archivos, subcarpetas y ficheros de subcarpetas. Para cada elemento de la tupla tenemos:\n",
    "- El directorio donde está apuntando.\n",
    "- Los directorios que hay ahí.\n",
    "- Los archivos que hay ahí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_generator = os.walk(os.getcwd())\n",
    "\n",
    "files_result = [x for x in result_generator]\n",
    "files_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué podemos hacer dentro de un directorio, aparte de listar ficheros y subdirectorios? Las principales operaciones serían:\n",
    "- Crear o eliminar directorios\n",
    "- Crear o eliminar ficheros\n",
    "- Mover ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('direct_prueba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rmdir('direct_prueba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/generated/fichero.txt\", \"w\")\n",
    "\n",
    "for i in range(10):\n",
    "    f.write(\"Line:\" + str(i)+\"\\n\")\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.move(\"data/generated/fichero.txt\", \"img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.path.dirname(os.path.abspath('__file__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.dirname('0-Lectura Escritura.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname('img/python.jpg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
